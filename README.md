BCG X â€“ Behavioral Analytics & Predictive Risk Modeling

A full end-to-end machine learning pipeline replicating a real consulting workflow for customer churn & risk prediction. This project demonstrates EDA, feature engineering, data cleaning, ML modeling, and stakeholder communication, aligned with how BCG X teams design analytical solutions.

Badges
![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Jupyter](https://img.shields.io/badge/Platform-Jupyter%20Notebook-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Project-Completed-brightgreen.svg)

 Project Overview

This project analyzes customer behavioral and financial data to identify early churn/risk indicators.
It includes:

Exploratory Data Analysis (EDA)

Data preprocessing & cleaning

Feature engineering of risk drivers

Predictive modeling using Random Forest

Hyperparameter tuning

Business insights & recommendations

The pipeline mirrors real consulting tasks delivered to a Senior Data Scientist.

Repository Structure & Filenames
ðŸ“„ Task 1 â€” Draft Email to Senior Data Scientist (Business Communication)

Filename: Task1_Draft_Email_Senior_Data_Scientist.docx

Purpose:
Professional written communication summarizing problem understanding, assumptions, risks, deliverables, and next steps.

Task 2 â€” EDA & Data Cleaning (Jupyter Notebook)

Filename:Task2_Exploratory_Data_Analysis_Data_Cleaning.ipynb

Includes:

Missing value analysis

Outlier detection

Univariate, bivariate, multivariate analysis

Distribution analysis (numerical & categorical)

Correlation heatmaps

Customer behavior pattern insights

Cleaning pipelines (imputation, encoding, scaling)

Technical Highlights:
pandas, numpy, matplotlib, seaborn, scikit-learn

Task 3 â€” Feature Engineering (Jupyter Notebook)

Filename:Task3_Feature_Engineering_Risk_Signals.ipynb

Includes:

Risk feature creation:

Billing volatility

Arrears & payment delays

Auto-pay dropout behavior

Plan-change frequency

Usage anomalies

Feature transformations

Feature selection methods

Encoding & scaling

Statistical modeling insights

Technical Highlights:
scikit-learn, feature_engine, pandas

Task 4 â€” Predictive Modeling (Random Forest + Tuning)

Filename:Task4_Predictive_Modeling_RandomForest_Hyperparameter_Tuning.ipynb

Includes:

Train/test split

Supervised learning model creation

Random Forest classifier

Hyperparameter tuning (GridSearchCV)

Recall-focused evaluation

Confusion matrix & feature importance

Risk-segment profiling

Technical Highlights:
RandomForestClassifier, GridSearchCV, classification_report, recall_score

MIT License
